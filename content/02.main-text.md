## Introduction {.page_break_before}

Gene expression profiles are widely used to classify samples or patients into relevant groups or categories, both preclinically [@doi:10.1371/journal.pcbi.1009926; @doi:10.1093/bioinformatics/btaa150] and clinically [@doi:10.1200/JCO.2008.18.1370; @pubmed:19914534].
To extract informative gene features and to perform classification, a diverse array of algorithms exist, and different algorithms perform well for different tasks [@doi:10.1371/journal.pcbi.1009926].
Even within a given model class, multiple optimization methods can often be applied to find well-performing parameters or to optimize a loss function.
One commonly used example is logistic regression.
The widely used scikit-learn package [@url:https://jmlr.org/papers/v12/pedregosa11a.html] provides two modules for fitting logistic regression classifiers: `LogisticRegression`, which provides the `liblinear` coordinate descent method [@url:https://www.jmlr.org/papers/v9/fan08a.html] for optimizing the model, and `SGDClassifier`, which uses stochastic gradient descent [@online-learning] to find parameters that optimize the model.

We compared these two optimization techniques for prediction of driver mutation status in tumor samples, across a wide variety of genes implicated in cancer initiation and development [@doi:10.1126/science.1235122].
We applied LASSO (L1-regularized) logistic regression, and tuned the strength of the regularization to compare model selection between optimizers.
We found that across a variety of models (i.e. regularization strengths), the training dynamics of the optimizers were considerably different: models fit using `liblinear` tended to perform best at fairly high regularization strengths (100-1000 nonzero features in the model) and overfit easily with low regularization strengths.
Models fit using stochastic gradient descent, on the other hand, tended to perform best at fairly low regularization strengths (10000+ nonzero features in the model), and overfitting was uncommon.



## Methods {.page_break_before}

## Results {.page_break_before}

## Discussion {.page_break_before}
